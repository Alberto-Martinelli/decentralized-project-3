{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Redundancy and Distributed Computing Workshop - TD3-A**  \n",
    "In this notebook we explore the transition from local computation to decentralized prediction models. We will develop multiple predictive models on a selected dataset, integrate them into an API, and introduce a **consensus mechanism** with a **slashing protocol** to enhance reliability in a decentralized setting.  \n",
    "\n",
    "_Authors_: Alessia SARRITZU, Alberto MARTINELLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Selection \n",
    "For this workshop, we decided to work with the **Titanic dataset**. It provides information about passengers aboard the Titanic, including their demographics, ticket class, and whether they survived the disaster.  \n",
    "\n",
    "**Core Features**\n",
    "- **Survived (`survived`)** – Target variable indicating whether the passenger survived (1 = Yes, 0 = No).  \n",
    "- **Passenger Class (`pclass`)** – The ticket class (1 = First, 2 = Second, 3 = Third).  \n",
    "- **Sex (`sex`)** – Gender of the passenger (`male` or `female`).  \n",
    "- **Age (`age`)** – Age of the passenger (may contain missing values).  \n",
    "- **Siblings/Spouses aboard (`sibsp`)** – Number of siblings/spouses traveling with the passenger.  \n",
    "- **Parents/Children aboard (`parch`)** – Number of parents/children traveling with the passenger.  \n",
    "- **Fare (`fare`)** – The fare paid for the ticket.  \n",
    "- **Embarked (`embarked`)** – Port of embarkation (`C` = Cherbourg, `Q` = Queenstown, `S` = Southampton).  \n",
    "\n",
    "**Additional Features**\n",
    "- **Class (`class`)** – Alternative representation of `pclass` (`First`, `Second`, `Third`).  \n",
    "- **Who (`who`)** – Categorizes passengers as `man`, `woman`, or `child` based on age and gender.  \n",
    "- **Adult Male (`adult_male`)** – Boolean flag (`True` = adult male, `False` = otherwise).  \n",
    "- **Deck (`deck`)** – Deck location of the cabin (many missing values).  \n",
    "- **Embark Town (`embark_town`)** – Full name of the embarkation town (`Southampton`, `Cherbourg`, `Queenstown`).  \n",
    "- **Alive (`alive`)** – String representation of survival status (`yes` or `no`).  \n",
    "- **Alone (`alone`)** – Boolean indicating if the passenger was traveling alone (`True` = alone, `False` = had family aboard).  \n",
    "\n",
    "Next, we will load and preprocess the dataset before developing individual predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning and Preprocessing\n",
    "\n",
    "Before training our machine learning models, it is essential to perform **data cleaning and preprocessing** to ensure that the dataset is free of inconsistencies, missing values, and irrelevant features. This step enhances model performance and ensures reliable predictions.  \n",
    "\n",
    "In this section, we:  \n",
    "1. **Load the Titanic dataset** and examine its structure.  \n",
    "2. **Analyze the class distribution** to understand the balance between survivors and non-survivors.  \n",
    "3. **Handle missing values**, specifically by dropping the `deck` column (which has excessive missing data) and removing any remaining incomplete rows.  \n",
    "4. **Prepare features for machine learning**, including encoding categorical variables (`sex`, `pclass`, and `embarked`) and standardizing numerical features (`age`, `sibsp`, `parch`, `fare`).  \n",
    "5. **Split the dataset into training and testing sets**, ensuring our models are evaluated fairly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = df['survived'].value_counts()\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values before cleaning: \n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n",
      "\n",
      "survived\n",
      "0    424\n",
      "1    288\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male  embark_town alive  alone  \n",
       "0    man        True  Southampton    no  False  \n",
       "1  woman       False    Cherbourg   yes  False  \n",
       "2  woman       False  Southampton   yes   True  \n",
       "3  woman       False  Southampton   yes  False  \n",
       "4    man        True  Southampton    no   True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(f\"Missing Values before cleaning: \\n{missing_values}\\n\")\n",
    "\n",
    "# Remove 'deck' column since it has many missing values\n",
    "df.drop(columns=['deck'], inplace=True)\n",
    "\n",
    "# Remove rows with any missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Check new class distribution\n",
    "class_distribution = df['survived'].value_counts()\n",
    "print(class_distribution)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Select features and target variable\n",
    "X = df[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "y = df['survived']\n",
    "\n",
    "# Define preprocessing pipeline\n",
    "scaler = StandardScaler()\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', scaler, ['age', 'sibsp', 'parch', 'fare']),\n",
    "    ('cat', OneHotEncoder(drop='first'), ['pclass', 'sex', 'embarked'])\n",
    "])\n",
    "\n",
    "# Split dataset into training & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply preprocessing to training & test data\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Practical Exercise: From Local to Decentralized Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q1** - Model Development and Deployment\n",
    "\n",
    "In this section, we will focus on building, evaluating, and deploying predictive models for the selected dataset. The key objectives are:\n",
    "\n",
    "- **Develop predictive models** : _Logistic Regression_, _Random Forest_ and _SVM_.\n",
    "- **Evaluate model accuracy and performance**: precision, recall, f1-score, accuracy.  \n",
    "- **Adapt the models for API access**: expose them via a Flask application with a GET `/predict` endpoint (`app.py`).\n",
    "- **Standardize the API response format**: ensure consistency across all models for seamless integration.\n",
    "```json\n",
    "    {\n",
    "        \"model\": \"<model_name>\",\n",
    "        \"input_features\": {\n",
    "            \"pclass\": 3,\n",
    "            \"sex\": \"male\",\n",
    "            \"age\": 22,\n",
    "            \"sibsp\": 1,\n",
    "            \"parch\": 0,\n",
    "            \"fare\": 7.25,\n",
    "            \"embarked\": \"S\"\n",
    "        },\n",
    "        \"prediction\": \"<Survived | Did not survive>\"\n",
    "    }\n",
    "```\n",
    "\n",
    "Additionally, the models deployed using Flask (`app.py`) can be tested through (`test.http`, section _Q1_). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        80\n",
      "           1       0.84      0.68      0.75        63\n",
      "\n",
      "    accuracy                           0.80       143\n",
      "   macro avg       0.81      0.79      0.80       143\n",
      "weighted avg       0.81      0.80      0.80       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict & evaluate\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
    "print(f'Logistic Regression Classification Report:\\n{classification_report(y_test, y_pred_logreg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81        80\n",
      "           1       0.78      0.71      0.74        63\n",
      "\n",
      "    accuracy                           0.78       143\n",
      "   macro avg       0.78      0.78      0.78       143\n",
      "weighted avg       0.78      0.78      0.78       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict & evaluate\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f'Random Forest Classification Report:\\n{classification_report(y_test, y_pred_rf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79        80\n",
      "           1       0.76      0.62      0.68        63\n",
      "\n",
      "    accuracy                           0.75       143\n",
      "   macro avg       0.75      0.73      0.74       143\n",
      "weighted avg       0.75      0.75      0.74       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train SVM model\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Predict & evaluate\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f'SVM Classification Report:\\n{classification_report(y_test, y_pred_svm)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/preprocessor.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save models & preprocessor\n",
    "joblib.dump(logreg, \"data/logreg_model.pkl\")\n",
    "joblib.dump(rf, \"data/rf_model.pkl\")\n",
    "joblib.dump(svm, \"data/svm_model.pkl\")\n",
    "joblib.dump(preprocessor, \"data/preprocessor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q2** - Consensus Model Development\n",
    "\n",
    "In this section, we will focus on implementing a **consensus-based prediction model** that aggregates the outputs from multiple individual models to enhance reliability and robustness. The key objectives are:\n",
    "\n",
    "- **Develop a consensus model** by averaging predictions from _Logistic Regression_, _Random Forest_, and _SVM_.  \n",
    "- **Expose the consensus model via API** using a Flask `/predict/consensus` endpoint (`app.py`).  \n",
    "- **Evaluate performance** of the consensus model.\n",
    "- **Ensure inter-computer connectivity** using **ngrok**, allowing external systems to access the prediction service.\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; align-items: center;\">\n",
    "    <img src=\"../images/ngrok-activation.png\" alt=\"NGROK Activation\" width=\"500\">\n",
    "    <img src=\"../images/ngrok-consensus.png\" alt=\"NGROK Consensus\" width=\"500\">\n",
    "</div>\n",
    "<br>  \n",
    "\n",
    "To maintain consistency with individual model predictions, the **consensus model API** response format follows the same structured response:\n",
    "```json\n",
    "{\n",
    "    \"model\": \"consensus\",\n",
    "    \"input_features\": {\n",
    "        \"pclass\": 3,\n",
    "        \"sex\": \"male\",\n",
    "        \"age\": 22,\n",
    "        \"sibsp\": 1,\n",
    "        \"parch\": 0,\n",
    "        \"fare\": 7.25,\n",
    "        \"embarked\": \"S\"\n",
    "    },\n",
    "    \"individual_predictions\": {\n",
    "        \"logistic_regression\": \"Did not survive\",\n",
    "        \"random_forest\": \"Survived\",\n",
    "        \"svm\": \"Did not survive\"\n",
    "    },\n",
    "    \"final_prediction\": \"<Survived | Did not survive>\"\n",
    "}\n",
    "```\n",
    "The **final consensus prediction** is determined by averaging the outputs of all models and rounding the result. <br>\n",
    "The model, deployed using Flask (`app.py`) can be tested through (`test.http`, section _Q2_) or through **ngrok** if the local server is running. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consensus Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83        80\n",
      "           1       0.84      0.65      0.73        63\n",
      "\n",
      "    accuracy                           0.79       143\n",
      "   macro avg       0.80      0.78      0.78       143\n",
      "weighted avg       0.80      0.79      0.79       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions for the test set using all models\n",
    "individual_preds = {model: model.predict(X_test) for model in [logreg, rf, svm]}\n",
    "\n",
    "# Compute consensus predictions\n",
    "consensus_preds = np.round(np.mean(np.array(list(individual_preds.values())), axis=0))\n",
    "\n",
    "# Evaluate accuracy\n",
    "consensus_accuracy = accuracy_score(y_test, consensus_preds)\n",
    "print(f\"Consensus Model Classification Report:\\n{classification_report(y_test,consensus_preds)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introducing Consensus with Slashing Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Q3** - Weighted Consensus Model\n",
    "\n",
    "In this section, we enhance the consensus model by introducing a dynamic weighting system to refine predictions based on each model's performance over time. Instead of treating all models equally, we adjust their influence on the final prediction using dynamically updated weights. <br>\n",
    "The key objectives are:\n",
    "\n",
    "- Implement a weighting system where model contributions are adjusted based on accuracy.\n",
    "- Weights range from 0 to 1, reflecting each model's reliability in past predictions.\n",
    "- Weights are updated per batch, refining consensus predictions as more data is processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Weights: [0.34943742 0.33707892 0.31348366]\n",
      "\n",
      "Final Weighted Consensus Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83        80\n",
      "           1       0.84      0.65      0.73        63\n",
      "\n",
      "    accuracy                           0.79       143\n",
      "   macro avg       0.80      0.78      0.78       143\n",
      "weighted avg       0.80      0.79      0.79       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Compute initial model accuracies\n",
    "model_accuracies = {\n",
    "    \"logistic_regression\": accuracy_score(y_test, y_pred_logreg),\n",
    "    \"random_forest\": accuracy_score(y_test, y_pred_rf),\n",
    "    \"svm\": accuracy_score(y_test, y_pred_svm)\n",
    "}\n",
    "\n",
    "# Normalize initial weights to sum to 1\n",
    "weights = np.array(list(model_accuracies.values()))\n",
    "weights /= weights.sum()  \n",
    "\n",
    "# Function to dynamically update weights\n",
    "def update_weights(y_true, predictions, weights, learning_rate=0.1):\n",
    "    \"\"\"\n",
    "    Adjust weights dynamically after each batch based on how well each model agrees with the true labels.\n",
    "    \"\"\"\n",
    "    predictions = np.array(predictions)  \n",
    "    y_true = np.array(y_true).flatten() \n",
    "\n",
    "    # Compute per-model accuracy in this batch\n",
    "    correct_predictions = (predictions.T == y_true).T  \n",
    "    accuracy_adjustments = correct_predictions.mean(axis=0)  \n",
    "    # Apply weighted adjustment\n",
    "    weights = weights * (1 + learning_rate * (accuracy_adjustments - weights))\n",
    "\n",
    "    # Normalize weights to sum to 1\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    return weights\n",
    "\n",
    "# Simulate multiple batches of predictions\n",
    "batch_size = 10\n",
    "num_batches = len(y_test) // batch_size\n",
    "pred_array = np.column_stack([preds.reshape(-1, 1) for preds in individual_preds.values()])\n",
    "\n",
    "for i in range(num_batches):\n",
    "    batch_start = i * batch_size\n",
    "    batch_end = batch_start + batch_size\n",
    "\n",
    "    # Get batch data\n",
    "    batch_y = y_test.iloc[batch_start:batch_end].values  \n",
    "    batch_preds = pred_array[batch_start:batch_end]  \n",
    "\n",
    "    # Compute weighted consensus prediction\n",
    "    weighted_preds = np.round(np.average(batch_preds, axis=1, weights=weights)).astype(int)\n",
    "\n",
    "    # Update weights based on batch performance\n",
    "    weights = update_weights(batch_y, batch_preds, weights)\n",
    "\n",
    "\n",
    "weights_dict = dict(zip([\"logistic_regression\", \"random_forest\", \"svm\"], weights.tolist()))\n",
    "with open(\"data/model_weights.json\", \"w\") as f:\n",
    "    json.dump(weights_dict, f)\n",
    "\n",
    "print(f\"\\nFinal Weights saved to data/model_weights.json: {weights_dict}\")\n",
    "print(f\"\\nFinal Weighted Consensus Classification Report:\\n{classification_report(y_test, np.round(np.average(pred_array, axis=1, weights=weights)).astype(int))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
